<html>
<title>SANS Notes</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="w3.css">
<link rel="stylesheet" href="w3-theme-black.css">
<link rel="stylesheet" href="roboto.css">
<link rel="stylesheet" href="font-awesome.min.css">


<style>
html,body,h1,h2,h3,h4,h5,h6 {font-family: "Roboto", sans-serif;}
.w3-sidebar {
  z-index: 3;
  width: 350px;
  top: 35px;
  bottom: 0;
  height: inherit;
  text-align: justify;}
</style>

<body>

<!-- Topbar -->
<div class="w3-top">
  <div class="w3-bar w3-theme w3-top w3-left-align w3-small">
    <a class="w3-bar-item w3-theme-l1"><i class="fa fa-bars"></i></a>
  </div>
</div>

<!-- Sidebar -->
<nav class="w3-sidebar w3-bar-block w3-collapse w3-small w3-theme-l5" id="mySidebar">
  <a class="w3-button w3-hover-black" href="cole.html">SEC 401 - Security Essentials, Cole</a>
  <a class="w3-button w3-hover-black" href="beaupre.html">SEC 460 - Threat/Vulnerability Management, Beaupre</a>
  <a class="w3-button w3-hover-black" href="cole2.html">SEC 501 - Enterprise Defender, Cole</a>
  <a class="w3-button w3-hover-black" href="brenton.html">SEC 502 - Perimeter Protection, Brenton</a>
  <a class="w3-button w3-hover-black" href="novak.html">SEC 503 - Intrusion Detection, Novak</a>
  <a class="w3-button w3-hover-black" href="strand.html">SEC 504 - Hacker Tools, Strand</a>
  <a class="w3-button w3-hover-black" href="pomeranz.html">SEC 506 - Linux/Unix Security, Pomeranz</a>
  <a class="w3-button w3-hover-black" href="hoelzer.html">SEC 507 - Auditing Networks, Hoelzer</a>
  <a class="w3-button w3-hover-black" href="misenar.html">SEC 511 - Continuous Monitoring, Misenar</a>
  <a class="w3-button w3-hover-black" href="skoudis.html">SEC 517 - Cutting Edge Hacking Techniques, Skoudis</a>
  <a class="w3-button w3-hover-black" href="strand2.html">SEC 550 - Offensive Countermeasures, Strand</a>
  <a class="w3-button w3-hover-black" href="henderson.html">SEC 555 - SIEM with Tactical Analytics, Henderson</a>
  <a class="w3-button w3-hover-black" href="skoudis2.html">SEC 560 - Network Penetration Testing, Skoudis</a>
  <a class="w3-button w3-hover-black" href="wright.html">SEC 561 - Hands-On Hacking Techniques, Wright</a>
  <a class="w3-button w3-hover-black" href="vest.html">SEC 564 - Red Team Operations, Vest</a>
  <a class="w3-button w3-hover-black" href="tarala.html">SEC 566 - Implementing Critical Security Controls, Tarala</a>
  <a class="w3-button w3-hover-black" href="baggett.html">SEC 573 - Automating InfoSec with Python, Baggett</a>
  <a class="w3-button w3-hover-black" href="buggenhout.html">SEC 599 - Defeating Advanced Adversaries, Buggenhout</a>
  <a class="w3-button w3-hover-black" href="wright2.html">SEC 617 - Wireless Ethical Hacking, Wright</a>
  <a class="w3-button w3-hover-black" href="searle.html">SEC 642 - Web App Penetration Testing, Searle</a>
  <a class="w3-button w3-hover-black" href="sims.html">SEC 660 - Advanced Penetration Testing, Sims</a>
  <a class="w3-button w3-hover-black" href="sims2.html">SEC 760 - Advanced Exploit Development, Sims</a>
  <a class="w3-button w3-hover-black" href="lee.html">FOR 408 - Windows Forensic Analysis, Lee</a>
  <a class="w3-button w3-hover-black" href="lee2.html">FOR 508 - Incident Response Forensics, Lee</a>
  <a class="w3-button w3-hover-black" href="hagen.html">FOR 572 - Advanced Network Forensics, Hagen</a>
  <a class="w3-button w3-hover-black" href="zeltser.html">FOR 610 - Reverse-Engineering Malware, Zeltser</a>
  <a class="w3-button w3-hover-black" href="cole3.html">MGT 414 - CISSP, Cole</a>
</nav>

<div class="w3-main" style="margin-left:350px">
  <div class="w3-row w3-padding-64">
    <div class="w3-twothird w3-container">
      <h2 class="w3-text-teal"></h2>

<h2>
    Thinking About Security, Steven Bellovin
</h2>
<p>
    The <strong><mark>root of the problem</strong></mark> is twofold: we're protecting (and
    spending money on protecting) the wrong things, and we're hurting
    productivity in the process... The solution, though of course easier said
    than done, is similarly twofold: protect the right things, and make it easy
    for employees to do the right thing.
</p>
<p>
    Security starts by knowing what you're protecting and against whom. A
    corollary to this is that any security advice that doesn't start with those
    two questions is wrong: you'll spend too much effort on the wrong things.
</p>
<p>
    Defense is also about money. It makes no sense to spend more money to
    protect an asset than you have at risk. There's a saying that bears
    remembering: "Amateurs worry about algorithms; pros worry about economics."
    Your goal is not to make a system penetration impossible; rather, it's to
    make it too expensive for your enemies, while not spending too much
    yourself.
</p>
<p>
    You have to have good passwords, but you have to protect them in the right
    way against the right threats. There is no perfect answer. Making the best
    choice requires understanding the interactions, the trade-offs, and the
    threats. In other words, a checklist will not suffice; you have to
    understand why to do things.
</p>
<p>
    <strong><mark>Security decisions</strong></mark>
    cannot be made in a vacuum. There's a large human element to worry about;
    security solutions that are not matched to people's behavior, good and bad,
    will fail.
</p>
<p>
    From a security perspective, though, <strong><mark>complexity</strong></mark> is fatal.
    No one understands a complex system, from the architects and programmers
    who design and build it to the engineers who have to configure it. A 1994
    study showed that about 25% of security flaws were due to bugs in the
    specification, not the code. In other words, it's not just a programming
    problem.
</p>
<p>
    The best approach to dealing with change is <strong><mark>analysis</strong></mark>.
    Naturally, everyone intends to do it, but it isn't easy. Doing it right
    requires approaching the problem de novo, rather than taking shortcuts.
    What are the components of the new system? What are their black-box
    properties? What else do we know or can we guess about them? What are their
    inputs and outputs?
</p>
<p>
    How are things combined? Is every input "secure"? If not, how can it be
    made secure?
</p>
<p>
    The <strong><mark>proper process</strong></mark> looks like this: while true repeat:
</p>
<p>
    &#8226; Identify the assets at risk.
</p>
<p>
    &#8226; Ascertain the enemies interested in each asset, and assess their
    likely capabilities.
</p>
<p>
    &#8226; Select application technologies.
</p>
<p>
    &#8226; Evaluate the vulnerabilities for each piece.
</p>
<p>
    &#8226; Identify candidate defensive solutions.
</p>
<p>
    &#8226; Estimate the cost, including the cost in damage to the application
    if security is breached.
</p>
<h2>
    Thinking About Security
</h2>
<p>
    For most people it's remarkably hard to think like a bad guy. Nevertheless,
    the ability to do so is at the heart of what security people have to do....
    A security person will look at a mechanism and think, "What else can this
    do? What can it do that will serve my needs rather than the intended
    purpose?"
</p>
<p>
    One way to "<strong><mark>think sideways</strong></mark>" is to consider every process
    as a series of steps. Each step, in turn, depends on a person or gadget
    accepting a series of inputs. Ask yourself this: what if one of those
    inputs was wrong or corrupted? Would something useful happen? Do I have the
    ability to cause that input to be wrong?
</p>
<p>
    Is the cost of the defense more or less than the losses from this attack?
    This is a crucial point that every security person should memorize and
    repeat daily: the purpose of security is not to increase security; rather,
    its purpose is to prevent losses. Any unnecessary expenditure on security
    is itself a net loss.
</p>
<p>
    Security is an economic decision. You are trying to protect certain assets,
    tangible or not; these have a certain monetary value. Your goal is to spend
    less protecting them than they're worth.
</p>
<p>
    The more moving parts a system has, the harder it is to analyze. Quite
    simply, if code doesn't exist, it can't be subverted. As always, complexity
    is your enemy.
</p>
<p>
    When trying to emulate the enemy, the most important single question is
    what the <strong><mark>weak points</strong></mark> are. That is, what system components
    are more likely to be penetrated. There is no absolute way to measure this,
    but there are a few rules of thumb:
</p>
<p>
    &#8226; A module that processes input from the outside is more vulnerable.
    &#8226; A privileged module is more likely to be targeted.
</p>
<p>
    &#8226; All other things being equal, a more complex module or system is
    more likely to have security flaws.
</p>
<p>
    &#8226; The richer the input language a module accepts, the more likely it
    is that there are parsing problems.
</p>
<h2>
    Threat Models
</h2>
<p>
    The correct answer to most simple security questions is "it depends."
    Security isn't a matter of absolutes; it's a matter of picking the best set
    of strategies given assorted constraints and objectives.
</p>
<p>
    Most of the spam you receive is sent from hacked personal computers. This
    has an important consequence: any Internet-connected computer- that is to
    say, most of them-is of value to many attackers. Maybe your computer
    doesn't have defense secrets and maybe you never log on to your bank from
    it, but if it can send email, it's useful to the bad guys and thus has to
    be protected.
</p>
<p>
    An APT attacker won't be stopped by the strongest cryptography, either.
    There are probably other weaknesses in the victim's defenses; why bother
    going through a strong defense when you can go around it? It's easier to
    plant some malware on the endpoint; such code can read the plaintext before
    it's encrypted or after it's decrypted. Better yet, the malware can include
    a keystroke logger, which can capture the passwords used to encrypt files.
</p>
<p>
    "What do I have that an attacker-any attacker-might want?" Generically
    speaking, every computer has certain things: an identity, bandwidth, and
    credentials.... To a first approximation, every computer is at risk; the
    excuse that "there's nothing interesting on this machine" is exactly that:
    an excuse. This fact is the base level from which all risk assessments must
    start.
</p>
<h2>
    Antivirus Software
</h2>
<p>
    Today's virus checkers rely primarily on signatures: they match files
    against a database of code snippets of known viruses. The code matched can
    be part of the virus' replication mechanism or its payload.
</p>
<p>
    The disadvantages of this sort of pattern-matching are obvious. One, of
    course, is that its success is crucially dependent on having a complete,
    up-to-date signature database. The antivirus companies love that, since it
    means that customers have to buy subscriptions rather than make a onetime
    purchase, but it's entirely legitimate; by definition a new virus won't be
    matched by anything in an older database.
</p>
<p>
    Virus writers have used the obvious counter to signature databases; they've
    employed various forms of obfuscation and transformation of the actual
    virus. Some viruses encrypt most of the body, in which case the antivirus
    software has to recognize the decryptor. Other viruses do things like
    inserting NOPs, rearranging code fragments, replacing instruction sequences
    with equivalent ones, and so on.
</p>
<p>
    Many people suggest running two different brands of antivirus software to
    take advantage of different collections of viruses.... One solution is to
    use one technology at network entry points-mail gateways, web proxies, and
    perhaps file servers-while using a different technology on end systems.
    That also helps deal with the cost issue; you don't have to buy two
    different packages for each of your many desktops and laptops.
</p>
<p>
    In essence, a sandbox can do two things: it can reduce both the effective
    instruction set and the effective target environment of programs executed
    within it. Taken together, these properties can drastically reduce or even
    stop the spread of viruses and worms.
</p>
<h2>
    Firewalls and Intrusion Detection Systems
</h2>
<p>
    There are three properties necessary for a firewall to be effective:
</p>
<p>
    1. There must exist a <strong><mark>topological chokepoint</strong></mark> at which to
    place a firewall.
</p>
<p>
    2. The nodes on the "inside" of the firewall share the same security
    policy. 3. All nodes on the "inside" must be "good"; all nodes on the
    outside are, if not actually "bad," untrusted.
</p>
<p>
    When one or more of these conditions does not hold, a firewall cannot
    succeed. Today, none are true for the typical enterprise.
</p>
<p>
    Property 1 fails because of the number of links a typical company has,
    links that do not go through "the" firewall. These links may be to
    suppliers, customers, joint venture partners, outsourcees, what have you.
</p>
<p>
    Property 2 fails because of the number of computers used today. With so
    many nodes, the policies have to differ drastically. When firewalls first
    became popular, only a small subset of employees needed Internet
    connectivity.
</p>
<p>
    Property 3 fails, too, partly because of the large population on the
    inside, and partly because of mobile nodes: if they get infected when
    they're on the outside, they're effectively bad guys when inside the
    firewall.
</p>
<p>
    The solution is a <strong><mark>point firewall</strong></mark>, a simple firewall in
    front of a limited set of resources. Point firewalls work because of their
    scope: they are not trying to protect arbitrarily many devices, they are
    not enforcing complex rules, they are not dealing with thousands of
    exceptions. There is also a more subtle philosophical difference: their
    primary function is not just bug deflection; rather, they are add-on access
    control mechanisms.
</p>
<p>
    Small-scale firewalls, protecting a network about the size run by a single
    system administrator, still serve a useful function. Generally speaking,
    these will be packet filters and hence not require extra hardware.
</p>
<p>
    An enterprise firewall retains value against low-skill attackers but is
    actually a point of risk, not protection, when trying to filter complex
    protocols against sophisticated adversaries. If you have such services that
    must be accessible from the outside, use packet filtering on the enterprise
    firewall and a separate protection layer near the server itself.
</p>
<p>
    Arguably, mobile devices-laptops, tablets, smart phones-should never be
    fully trusted, not because they use wireless connections, but because
    they're much more likely to carry malware.
</p>
<p>
    An intrusion detection system (IDS) is a backup security mechanism. It
    assumes that your other defenses-firewalls, hardened hosts--have failed.
    The task then is to notice the successful attack as soon as possible, which
    permits minimization of the damage, either via automated systems or their
    backup humans.
</p>
<p>
    Doing intrusion detection in the network, by grabbing packets in flight, is
    difficult. The obvious problem is dealing with encrypted traffic; more
    seriously, it's all too easy to miss packets.
</p>
<p>
    More sophisticated network monitoring can be done as well. There are
    comparatively simple systems that look for simple patterns of data, such as
    Bro or Snort.
</p>
<p>
    There are a number of ways to perform <strong><mark>extrusion detection</strong></mark>.
    One of the simplest is the honeypot: create fake files that will attract
    the attention of a spy, commercial or governmental, and wait for someone to
    grab one.
</p>
<p>
    There are some interesting wrinkles here that makes extrusion detection
    harder in some ways than firewalls or intrusion detection. For one thing,
    someone exporting information is freer to use encryption.
</p>
<p>
    Even if encryption is used, the defenders aren't helpless. While crypto
    does hide the precise content being sent, it can't hide the volume; more
    importantly, encrypted data has a very unique flat byte distribution; this,
    too, is anomalous if from a source or to a destination that does not
    normally receive such.
</p>
<p>
    One can view intrusion and extrusion detection systems as in some sense the
    dual of firewalls. The latter attempts to prevent trouble; the former
    attempt to detect it. Firewalls are primarily concerned with what the
    communications endpoints and protocols are; detection systems are more
    concerned with the contents. Firewalls are generally centralized; detection
    systems function better if decentralized.
</p>
<p>
    Extrusion detection is even more challenging than policy enforcement.
    Generally speaking, physical access wins; it is very hard to prevent the
    owner of a device from getting at any or all of its contents. One thing
    that will help is if vendors implement a distributed logging system.
</p>
<p>
    What is really needed is a way for packets or messages of security interest
    to be flagged reliably, thus simplifying policy enforcement. Until that
    happens, all of these mechanisms will be imperfect.
</p>
<h2>
    Cryptography
</h2>
<p>
    "Insecurity is like entropy: it can't be destroyed, but it can be moved
    around. With cryptography, we substitute the insecurity of the key for the
    insecurity of the data, because we think we can protect the keys better."
</p>
<p>
    Cryptography is a very difficult and subtle branch of applied mathematics;
    remarkably few people are qualified to practice it. Never use a proprietary
    encryption algorithm, especially if you're told that it's more secure
    because it's secret. The same applies to cryptographic protocols; they're
    also quite hard to get right.
</p>
<p>
    Signed code will often be accepted silently by Windows systems; if malware
    is signed-and it has been-it can easily be installed without the user
    noticing anything.
</p>
<h2>
    Passwords and Authentication
</h2>
<p>
    Most discussions of authentication start by describing the three basic
    forms: something you know (e.g., a password); something you have, such as a
    token or a particular mobile phone; and something you are, that is, some
    form of biometric. While this categorization is indeed useful, it
    understates the systems nature of authentication.
</p>
<p>
    The <strong><mark>total environment</strong></mark> -who will use it, how you deal with
    lost credentials, what the consequences are of lack of access or access by
    the wrong person, and more-is at least as important. The most important
    question of all is how people will actually use the authentication
    technology in the real world.
</p>
<p>
    Password authentication, that much-maligned mechanism, is better than most
    when it comes to granting temporary access or the need to trust external
    parties. Most alternatives concentrate on the most glaring issues with
    passwords, users forgetting their passwords, attackers guessing them, or
    capture of a password by phishing sites or keystroke loggers. Almost all
    are weaker under other circumstances.
</p>
<p>
    Passwords are not suitable for high-security needs. This includes most
    logins for medium and large enterprises. Even smaller enterprises should
    move away from passwords if the threat model so indicates.
</p>
<p>
    It will be a very long time before web sites convert to any other
authentication mechanism. Accordingly, technical means, such as    <strong><mark>password managers</strong></mark>, should be used to cope with the
    password reuse problem.
</p>
<p>
    Implement <strong><mark>bilateral authentication</strong></mark>; it's strong protection
    against phishing. Some password managers do this automatically: they'll
    send a password only if they recognize the site, and they're not fooled by
    clever email messages.
</p>
<h2>
    Building Secure Systems
</h2>
<p>
    <strong><mark>Systems security</strong></mark>
    comprises four very different aspects: good basic technologies, correct
    coding, proper design, and secure operation. All of these are necessary; a
    weakness in any can spell disaster.
</p>
<p>
    When doing the analysis itself, the most important thing to remember is
    that attackers don't follow the rules. More specifically, they don't follow
    your notion of what can happen; they'll attack where they can. Always look
    more broadly.
</p>
<p>
    For that reason, I'm not fond of using attack trees or other top-down
    methodologies for security analysis. Those start by saying "to attack X,
    one must first penetrate Y or Z." Certainly, penetrating Y or Z will
    suffice, but that approach tends to favor known paths. Instead, go
    bottom-up: look at each computer, assume that it's been compromised, and
    see what can happen.
</p>
<p>
    Understanding and evaluating a system is not a simple task. Indeed, just
    understanding the threats is difficult. The essence is to approach the
    questions systematically. A very high percentage of failures occur because
    designers or evaluators completely overlooked some aspect of the
    architecture, or because they underestimated the skills and resources of
    potential enemies. If you look at every component and every link, asking
    yourself who could compromise it and what the effects would be, you're much
    more likely to get the right answer.
</p>
<h2>
    People
</h2>
<p>
    There is a human, not technical, link in the chain of weaknesses that can
    lead to trouble. It is tempting to try to fix such problems via technical
    means. For better or worse, that's not always possible. The answer is
    threefold: <strong><mark>training, education, and incentives</strong></mark>. Sadly,
    most companies stop after the first.
</p>
<p>
    The hardest problem to deal with is when a user has been tricked. You can
    say that more education or training would have helped, or perhaps better
    adherence to rules. It's not that simple. Security is an adversarial
    process, which means that you're pitting experts in deception-the
    attackers-against people who may be very competent at their own jobs but
    who aren't security experts. Furthermore, the advantage is with the
    attacker, who only has to win once.
</p>
<p>
    There are no-repeat, no-strong technical defenses against social
    engineering, especially when it happens offline. The essence of the problem
    is an authorized person being tricked or coerced into doing something
    permissible but for improper reasons. Sometimes, process will help, but if
    and only if people follow it religiously.
</p>
<p>
    Ultimately, there is no cure for gullibility. I've often repeated that
    security is a systems problem; people have to be considered part of the
    system, too.
</p>
<h2>
    Security Process
</h2>
<p>
    Most organizations will have a "deny by default" basic policy. Thus, we
    start by identifying the desired functionality... The next step is to
    evaluate the different options for both cost and security risks. For
    large-enough projects, it may pay to bring in Legal: can some of the risks
    be ameliorated by a contract with some external party? Should you impose
    some security requirements on that party? Remember that the goal is not
    security at any cost, it's security commensurate with the cost/benefit
    trade-off.
</p>
<p>
    If your policy is "default accept"-many, though not all, universities are
    that way-you need a somewhat different process. Start with the assets to be
    protected and the threats to them, then lay out the defensive options.
</p>
<h2>
    Doing Security Properly
</h2>
<p>
    Attacks (and especially serious attacks) don't happen simply because
    they're possible; rather, they happen because someone somehow gains
    something from the attack. Recall the definition of a threat cited in
    Chapter
</p>
<p>
    3: "an adversary that is motivated and capable of exploiting a
    vulnerability." You need all three to have a problem: the vulnerability,
    the capability, and the motivation. Looking at this through a purely
    technological lens makes you focus on the first two, but the third is
    equally critical.
</p>
<p>
Most of our systems are based on what I call the    <strong><mark>"walls and doors principle": </strong></mark>a strong wall between
    security contexts, and a door, an opening in the wall for selected
    requests. We're pretty good (though not perfect) at building walls, that
    is, at separating contexts. Doors, though, are problematic. They're not
    supposed to pass just any request; rather, they should do so only in
    accordance with a policy. Unfortunately, both specifying and implementing
    suitable policies is difficult.
</p>


<!-- END MAIN -->
</div>

<script>
// Get the Sidebar
var mySidebar = document.getElementById("mySidebar");

// Get the DIV with overlay effect
var overlayBg = document.getElementById("myOverlay");

// Toggle between showing and hiding the sidebar, and add overlay effect
function w3_open() {
    if (mySidebar.style.display === 'block') {
        mySidebar.style.display = 'none';
        overlayBg.style.display = "none";
    } else {
        mySidebar.style.display = 'block';
        overlayBg.style.display = "block";
    }
}

// Close the sidebar with the close button
function w3_close() {
    mySidebar.style.display = "none";
    overlayBg.style.display = "none";
}
</script>

</body>
</html>
